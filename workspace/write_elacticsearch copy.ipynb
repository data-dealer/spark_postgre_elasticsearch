 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c2ba3-eee9-4419-974b-1fbcbbf26cc3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Py4JJavaError: An error occurred while calling o73.save.\n",
    "# : java.lang.NoClassDefFoundError: org/apache/commons/httpclient/protocol/ProtocolSocketFactory\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master('spark://host.docker.internal:7077')\n",
    "    .appName(\"pytest\")\n",
    "    # .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-hadoop:8.12.1\")\n",
    "    # .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-spark-30_2.12:7.12.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0\")\n",
    "    .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-spark-30_2.12:7.12.0,commons-httpclient:commons-httpclient:3.1\")\n",
    "    # .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    # .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddd335-7c67-4bc4-81c1-a8efc2bb30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0a2080da-0c9f-4348-8e99-c1de9b93e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def random_int(min_value, max_value):\n",
    "  return random.randint(min_value, max_value)\n",
    "    \n",
    "data = [\n",
    "    (fake.uuid4(),\n",
    "     fake.name(),\n",
    "     random_int(20, 65),\n",
    "     fake.city(),\n",
    "     fake.job(),\n",
    "     random_int(50000, 200000),\n",
    "     random.choice([\"Male\", \"Female\"]),\n",
    "     random_int(160, 190),\n",
    "     random_int(50, 100),\n",
    "     random.choice([True, False]),\n",
    "     fake.date_of_birth(),\n",
    "     fake.color_name(),\n",
    "     fake.text()\n",
    "    )\n",
    "    for _ in range(1000)]\n",
    "\n",
    "# Create DataFrame with 12 Columns\n",
    "df = spark.createDataFrame(data, schema=[\n",
    "    \"id\", \"name\", \"age\", \"city\", \"department\", \"salary\", \"gender\", \n",
    "    \"height\", \"weight\", \"isActive\", \"join_date\", \"favorite_color\",\n",
    "    \"note\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66c50211-d0a8-49d2-8857-ebdc2141db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e814c-8e53-495f-a613-8ff70187ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c014c54-881a-4f7f-b3d9-21abb7b57f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_nodes = \"http://host.docker.internal:9200\"\n",
    "es_resource = \"customer_index/_doc\"\n",
    "\n",
    "esconf={\n",
    "    \"es.mapping.id\": \"id\",\n",
    "    \"es.mapping.exclude\": \"id\",\n",
    "    \"es.nodes\": \"http://host.docker.internal\",\n",
    "    \"es.port\": \"9200\",\n",
    "    \"es.update.script.inline\": \"ctx._source.location = params.type\",\n",
    "    \"es.write.operation\": \"upsert\"   \n",
    "}\n",
    "start_time = time.time()\n",
    "df.write.format(\"org.elasticsearch.spark.sql\").options(**esconf).mode(\"append\").save(es_resource)\n",
    "total_time = (time.time() - start_time)/60\n",
    "print('total time:', total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dd10e130-4b29-40be-99b1-a87ce560809a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'toPandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~tmp/ipykernel_20/3345818877.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbulk_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbulk_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Optional: Implement logic to generate unique IDs if not using document IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~opt/bitnami/python/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'toPandas'"
     ]
    }
   ],
   "source": [
    "bulk_data = df.toPandas().to_dict('records')\n",
    "bulk_body = []\n",
    "def generate_id(doc):\n",
    "    # Optional: Implement logic to generate unique IDs if not using document IDs\n",
    "    return doc['id']  # Use existing 'id' column as document ID (example)\n",
    "\n",
    "for doc in bulk_data:\n",
    "    # Add index operation and document to bulk body\n",
    "    operation = {\"index\": {\"_index\": 'customer_index_bulk', \"_id\": generate_id(doc)}}\n",
    "    bulk_body.append(operation)\n",
    "    bulk_body.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6080db11-ca2a-4af0-a8e0-761da899cc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': {'_index': 'my_index', '_id': 1}},\n",
       " {'id': 1,\n",
       "  'title': 'Document 1',\n",
       "  'content': 'This is the content of document 1.'},\n",
       " {'index': {'_index': 'my_index', '_id': 2}},\n",
       " {'id': 2,\n",
       "  'title': 'Document 2',\n",
       "  'content': 'This is the content of document 2.'},\n",
       " {'index': {'_index': 'my_index', '_id': 3}},\n",
       " {'id': 3,\n",
       "  'title': 'Document 3',\n",
       "  'content': 'This is the content of document 3.'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "149ab5b1-fb30-4122-8964-1c180c3ccb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [json.dumps(d, indent=2, sort_keys=True, default=str) for d in bulk_body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5344458d-ce42-4643-b098-d28df2797b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d69e669-226e-4c9f-aad3-9dc25d12cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "headers = {'Content-Type': 'application/x-ndjson'}\n",
    "response = requests.post(es_nodes + \"/_bulk\", headers=headers, data=\"\\n\".join([json.dumps(d, indent=2, sort_keys=True, default=str) for d in bulk_body]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8402d07e-9d99-4296-b60e-c0d683960f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [400]>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84de19c2-fe30-4db3-bc7f-5868f573a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from elasticsearch import Elasticsearch\n",
    "# es = Elasticsearch(hosts=[\"http://host.docker.internal:9200\"])\n",
    "# response = es.bulk(index=\"customer_index_bulk2\", body=bulk_body[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ea28e77-f709-46ac-a484-3dd38200a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST \"localhost:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d'\n",
    "{ \"index\" : { \"_index\" : \"test\", \"_id\" : \"1\" } }\n",
    "{ \"field1\" : \"value1\" }\n",
    "{ \"delete\" : { \"_index\" : \"test\", \"_id\" : \"2\" } }\n",
    "{ \"create\" : { \"_index\" : \"test\", \"_id\" : \"3\" } }\n",
    "{ \"field1\" : \"value3\" }\n",
    "{ \"update\" : {\"_id\" : \"1\", \"_index\" : \"test\"} }\n",
    "{ \"doc\" : {\"field2\" : \"value2\"} }\n",
    "'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9514f1e7-bded-4432-a930-bb07c8edc517",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [\n",
    "    { \"index\" : { \"_index\" : \"test2\", \"_id\" : \"1\" } },\n",
    "    { \"field1\" : \"value1\" }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6a215a09-01fa-4c9a-a7d3-b17eeb475af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_bulk_api(df, _index = 'customer_index_bulk', _id = 'id'):\n",
    "    \"\"\"\n",
    "    df: spark DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    bulk_data = df.toPandas().to_dict('records')\n",
    "    bulk_body = []\n",
    "    def generate_id(doc):\n",
    "        return doc[_id]  # Use existing 'id' column as document ID (example)\n",
    "        \n",
    "    for doc in bulk_data:\n",
    "        operation = {\"index\": {\"_index\": _index, \"_id\": generate_id(doc)}}\n",
    "        bulk_body.append(operation)\n",
    "        bulk_body.append(doc)\n",
    "\n",
    "    start_time = time.time()\n",
    "    import os\n",
    "    text = \"\\n\".join(json.dumps(item, default=str) for item in bulk_data)\n",
    "    cmd = f\"\"\"curl -X POST \"host.docker.internal:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d '\n",
    "    {text}\n",
    "    '\n",
    "    \"\"\"\n",
    "    os.system(cmd)\n",
    "    # subprocess.check_output(cmd)\n",
    "    total_time = (time.time() - start_time)/60\n",
    "    print('total time:', total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2183b771-7586-4e9e-af90-85783d5761f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 0.00016139745712280275\n"
     ]
    }
   ],
   "source": [
    "insert_bulk_api(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c92c5fc1-7e7c-4ad2-bec9-d6197b0c8fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8797  100  8797    0     0   369k      0 --:--:-- --:--:-- --:--:--  390k\n"
     ]
    }
   ],
   "source": [
    "def checkcount(_index=customer_index):\n",
    "    import subprocess\n",
    "    ans = subprocess.check_output([\"curl\", \"-X GET\", \"host.docker.internal:9200/customer_index/_stats\"], text=True)\n",
    "    total = json.loads(ans)['_all']['primaries']['indexing']['index_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9d888a26-9e43-40fc-8965-a5b733a3c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4644696f-4965-451c-952f-2880c1b1fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"\"\"curl -X GET \"host.docker.internal:9200/customer_index/_stats\" \"\"\")['_all']#['primaries']['indexing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "32fa5d38-3248-4168-8098-d01fe36380e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -X POST \"host.docker.internal:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d '\n",
      "{\"index\": {\"_index\": \"test2\", \"_id\": \"1\"}}\n",
      "{\"field1\": \"value1\"}\n",
      "'\n",
      "\n",
      "{\n",
      "  \"took\" : 15,\n",
      "  \"errors\" : false,\n",
      "  \"items\" : [\n",
      "    {\n",
      "      \"index\" : {\n",
      "        \"_index\" : \"test2\",\n",
      "        \"_type\" : \"_doc\",\n",
      "        \"_id\" : \"1\",\n",
      "        \"_version\" : 2,\n",
      "        \"result\" : \"updated\",\n",
      "        \"_shards\" : {\n",
      "          \"total\" : 2,\n",
      "          \"successful\" : 1,\n",
      "          \"failed\" : 0\n",
      "        },\n",
      "        \"_seq_no\" : 1,\n",
      "        \"_primary_term\" : 1,\n",
      "        \"status\" : 200\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   471  100   406  100    65  13973   2237 --:--:-- --:--:-- --:--:-- 16821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "text = \"\\n\".join(json.dumps(item) for item in datas)\n",
    "cmd = f\"\"\"curl -X POST \"host.docker.internal:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d '\n",
    "{text}\n",
    "'\n",
    "\"\"\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a637da-3c89-4f93-a82c-d5a857e60060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POST _sql?format=txt\n",
    "{\n",
    "  \"query\": \"SELECT * FROM customer_index\"\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
#{"dirpath":"spark_postgre_elasticsearch/workspace","filename":"write_elacticsearch copy.ipynb"}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c2ba3-eee9-4419-974b-1fbcbbf26cc3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Py4JJavaError: An error occurred while calling o73.save.\n",
    "# : java.lang.NoClassDefFoundError: org/apache/commons/httpclient/protocol/ProtocolSocketFactory\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master('spark://host.docker.internal:7077')\n",
    "    .appName(\"pytest\")\n",
    "    # .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-hadoop:8.12.1\")\n",
    "    # .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-spark-30_2.12:7.12.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0\")\n",
    "    .config(\"spark.jars.packages\", \"org.elasticsearch:elasticsearch-spark-30_2.12:7.12.0,commons-httpclient:commons-httpclient:3.1\")\n",
    "    # .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    # .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddd335-7c67-4bc4-81c1-a8efc2bb30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0a2080da-0c9f-4348-8e99-c1de9b93e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def random_int(min_value, max_value):\n",
    "  return random.randint(min_value, max_value)\n",
    "    \n",
    "data = [\n",
    "    (fake.uuid4(),\n",
    "     fake.name(),\n",
    "     random_int(20, 65),\n",
    "     fake.city(),\n",
    "     fake.job(),\n",
    "     random_int(50000, 200000),\n",
    "     random.choice([\"Male\", \"Female\"]),\n",
    "     random_int(160, 190),\n",
    "     random_int(50, 100),\n",
    "     random.choice([True, False]),\n",
    "     fake.date_of_birth(),\n",
    "     fake.color_name(),\n",
    "     fake.text()\n",
    "    )\n",
    "    for _ in range(1000)]\n",
    "\n",
    "# Create DataFrame with 12 Columns\n",
    "df = spark.createDataFrame(data, schema=[\n",
    "    \"id\", \"name\", \"age\", \"city\", \"department\", \"salary\", \"gender\", \n",
    "    \"height\", \"weight\", \"isActive\", \"join_date\", \"favorite_color\",\n",
    "    \"note\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66c50211-d0a8-49d2-8857-ebdc2141db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e814c-8e53-495f-a613-8ff70187ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c014c54-881a-4f7f-b3d9-21abb7b57f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_nodes = \"http://host.docker.internal:9200\"\n",
    "es_resource = \"customer_index/_doc\"\n",
    "\n",
    "esconf={\n",
    "    \"es.mapping.id\": \"id\",\n",
    "    \"es.mapping.exclude\": \"id\",\n",
    "    \"es.nodes\": \"http://host.docker.internal\",\n",
    "    \"es.port\": \"9200\",\n",
    "    \"es.update.script.inline\": \"ctx._source.location = params.type\",\n",
    "    \"es.write.operation\": \"upsert\"   \n",
    "}\n",
    "start_time = time.time()\n",
    "df.write.format(\"org.elasticsearch.spark.sql\").options(**esconf).mode(\"append\").save(es_resource)\n",
    "total_time = (time.time() - start_time)/60\n",
    "print('total time:', total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dd10e130-4b29-40be-99b1-a87ce560809a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'toPandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~tmp/ipykernel_20/3345818877.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbulk_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbulk_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Optional: Implement logic to generate unique IDs if not using document IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~opt/bitnami/python/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'toPandas'"
     ]
    }
   ],
   "source": [
    "bulk_data = df.toPandas().to_dict('records')\n",
    "bulk_body = []\n",
    "def generate_id(doc):\n",
    "    # Optional: Implement logic to generate unique IDs if not using document IDs\n",
    "    return doc['id']  # Use existing 'id' column as document ID (example)\n",
    "\n",
    "for doc in bulk_data:\n",
    "    # Add index operation and document to bulk body\n",
    "    operation = {\"index\": {\"_index\": 'customer_index_bulk', \"_id\": generate_id(doc)}}\n",
    "    bulk_body.append(operation)\n",
    "    bulk_body.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6080db11-ca2a-4af0-a8e0-761da899cc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': {'_index': 'my_index', '_id': 1}},\n",
       " {'id': 1,\n",
       "  'title': 'Document 1',\n",
       "  'content': 'This is the content of document 1.'},\n",
       " {'index': {'_index': 'my_index', '_id': 2}},\n",
       " {'id': 2,\n",
       "  'title': 'Document 2',\n",
       "  'content': 'This is the content of document 2.'},\n",
       " {'index': {'_index': 'my_index', '_id': 3}},\n",
       " {'id': 3,\n",
       "  'title': 'Document 3',\n",
       "  'content': 'This is the content of document 3.'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "149ab5b1-fb30-4122-8964-1c180c3ccb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [json.dumps(d, indent=2, sort_keys=True, default=str) for d in bulk_body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5344458d-ce42-4643-b098-d28df2797b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d69e669-226e-4c9f-aad3-9dc25d12cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "headers = {'Content-Type': 'application/x-ndjson'}\n",
    "response = requests.post(es_nodes + \"/_bulk\", headers=headers, data=\"\\n\".join([json.dumps(d, indent=2, sort_keys=True, default=str) for d in bulk_body]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8402d07e-9d99-4296-b60e-c0d683960f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [400]>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84de19c2-fe30-4db3-bc7f-5868f573a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from elasticsearch import Elasticsearch\n",
    "# es = Elasticsearch(hosts=[\"http://host.docker.internal:9200\"])\n",
    "# response = es.bulk(index=\"customer_index_bulk2\", body=bulk_body[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ea28e77-f709-46ac-a484-3dd38200a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST \"localhost:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d'\n",
    "{ \"index\" : { \"_index\" : \"test\", \"_id\" : \"1\" } }\n",
    "{ \"field1\" : \"value1\" }\n",
    "{ \"delete\" : { \"_index\" : \"test\", \"_id\" : \"2\" } }\n",
    "{ \"create\" : { \"_index\" : \"test\", \"_id\" : \"3\" } }\n",
    "{ \"field1\" : \"value3\" }\n",
    "{ \"update\" : {\"_id\" : \"1\", \"_index\" : \"test\"} }\n",
    "{ \"doc\" : {\"field2\" : \"value2\"} }\n",
    "'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9514f1e7-bded-4432-a930-bb07c8edc517",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [\n",
    "    { \"index\" : { \"_index\" : \"test2\", \"_id\" : \"1\" } },\n",
    "    { \"field1\" : \"value1\" }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6a215a09-01fa-4c9a-a7d3-b17eeb475af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_bulk_api(df, _index = 'customer_index_bulk', _id = 'id'):\n",
    "    \"\"\"\n",
    "    df: spark DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    bulk_data = df.toPandas().to_dict('records')\n",
    "    bulk_body = []\n",
    "    def generate_id(doc):\n",
    "        return doc[_id]  # Use existing 'id' column as document ID (example)\n",
    "        \n",
    "    for doc in bulk_data:\n",
    "        operation = {\"index\": {\"_index\": _index, \"_id\": generate_id(doc)}}\n",
    "        bulk_body.append(operation)\n",
    "        bulk_body.append(doc)\n",
    "\n",
    "    start_time = time.time()\n",
    "    import os\n",
    "    text = \"\\n\".join(json.dumps(item, default=str) for item in bulk_data)\n",
    "    cmd = f\"\"\"curl -X POST \"host.docker.internal:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d '\n",
    "    {text}\n",
    "    '\n",
    "    \"\"\"\n",
    "    os.system(cmd)\n",
    "    # subprocess.check_output(cmd)\n",
    "    total_time = (time.time() - start_time)/60\n",
    "    print('total time:', total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2183b771-7586-4e9e-af90-85783d5761f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 0.00016139745712280275\n"
     ]
    }
   ],
   "source": [
    "insert_bulk_api(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c92c5fc1-7e7c-4ad2-bec9-d6197b0c8fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8797  100  8797    0     0   369k      0 --:--:-- --:--:-- --:--:--  390k\n"
     ]
    }
   ],
   "source": [
    "def checkcount(_index=customer_index):\n",
    "    import subprocess\n",
    "    ans = subprocess.check_output([\"curl\", \"-X GET\", \"host.docker.internal:9200/customer_index/_stats\"], text=True)\n",
    "    total = json.loads(ans)['_all']['primaries']['indexing']['index_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9d888a26-9e43-40fc-8965-a5b733a3c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4644696f-4965-451c-952f-2880c1b1fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"\"\"curl -X GET \"host.docker.internal:9200/customer_index/_stats\" \"\"\")['_all']#['primaries']['indexing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "32fa5d38-3248-4168-8098-d01fe36380e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -X POST \"host.docker.internal:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d '\n",
      "{\"index\": {\"_index\": \"test2\", \"_id\": \"1\"}}\n",
      "{\"field1\": \"value1\"}\n",
      "'\n",
      "\n",
      "{\n",
      "  \"took\" : 15,\n",
      "  \"errors\" : false,\n",
      "  \"items\" : [\n",
      "    {\n",
      "      \"index\" : {\n",
      "        \"_index\" : \"test2\",\n",
      "        \"_type\" : \"_doc\",\n",
      "        \"_id\" : \"1\",\n",
      "        \"_version\" : 2,\n",
      "        \"result\" : \"updated\",\n",
      "        \"_shards\" : {\n",
      "          \"total\" : 2,\n",
      "          \"successful\" : 1,\n",
      "          \"failed\" : 0\n",
      "        },\n",
      "        \"_seq_no\" : 1,\n",
      "        \"_primary_term\" : 1,\n",
      "        \"status\" : 200\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   471  100   406  100    65  13973   2237 --:--:-- --:--:-- --:--:-- 16821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "text = \"\\n\".join(json.dumps(item) for item in datas)\n",
    "cmd = f\"\"\"curl -X POST \"host.docker.internal:9200/_bulk?pretty\" -H 'Content-Type: application/json' -d '\n",
    "{text}\n",
    "'\n",
    "\"\"\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a637da-3c89-4f93-a82c-d5a857e60060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POST _sql?format=txt\n",
    "{\n",
    "  \"query\": \"SELECT * FROM customer_index\"\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
