spark.master=spark://spark-master:7077
spark.executor.memory=1G
spark.executor.cores=2
spark.executor.instances=2
spark.driver.memory=1G
spark.driver.cores=1
spark.cores.max=4
spark.default.parallelism=50
spark.sql.shuffle.partitions=100
spark.dynamicAllocation.enabled=false
log4j.logger.org.apache.hadoop.metrics2=ERROR
spark.ui.reverseProxy=true


# spark.history.fs.logDirectory=s3a://datalake/artifacts/sparklogs
# spark.eventLog.enabled=true
# spark.eventLog.dir=3a://artifacts

# # delta
spark.jars.packages=org.apache.hadoop:hadoop-aws:3.3.1,\
    org.elasticsearch:elasticsearch-spark-30_2.12:7.12.0

# org.apache.hadoop:hadoop-aws:3.3.1,\
#     io.delta:delta-core_2.12:2.3.0,\
#     org.apache.kafka:kafka-clients:3.2.1,\
#     org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1,\
#     org.mlflow:mlflow-spark_2.12:2.11.3,\


# ,com.amazon.deequ:deequ:jar:2.0.3-spark-3.3
# ,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1
# spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
# spark.sql.catalog.datalake=org.apache.spark.sql.delta.catalog.DeltaCatalog
